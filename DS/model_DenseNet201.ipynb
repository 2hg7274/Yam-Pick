{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Baseline Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 라이브러리 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
    "from tensorflow.keras.applications.densenet import DenseNet201\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, MaxPooling2D\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "\n",
    "from keras import regularizers\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop,SGD,Adamax\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "from silence_tensorflow import silence_tensorflow\n",
    "silence_tensorflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 103131 images belonging to 129 classes.\n",
      "Found 26209 images belonging to 129 classes.\n"
     ]
    }
   ],
   "source": [
    "PATH = '/Users/hanhyeongu/Desktop/codestates/CP1/Korea_Food_Image/'\n",
    "image_size = 150\n",
    "\n",
    "original_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = original_datagen.flow_from_directory(\n",
    "        PATH+'train',\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "val_generator = original_datagen.flow_from_directory(\n",
    "        PATH+'validation',\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '간장게장',\n",
       " 1: '갈비구이',\n",
       " 2: '갈비찜',\n",
       " 3: '갈비탕',\n",
       " 4: '갈치구이',\n",
       " 5: '갈치조림',\n",
       " 6: '감자전',\n",
       " 7: '감자조림',\n",
       " 8: '감자탕',\n",
       " 9: '갓김치',\n",
       " 10: '건새우볶음',\n",
       " 11: '경단',\n",
       " 12: '계란말이',\n",
       " 13: '계란찜',\n",
       " 14: '고등어구이',\n",
       " 15: '고등어조림',\n",
       " 16: '고사리나물',\n",
       " 17: '고추튀김',\n",
       " 18: '곱창구이',\n",
       " 19: '곱창전골',\n",
       " 20: '김밥',\n",
       " 21: '김치볶음밥',\n",
       " 22: '김치전',\n",
       " 23: '김치찌개',\n",
       " 24: '깍두기',\n",
       " 25: '깻잎장아찌',\n",
       " 26: '꼬막찜',\n",
       " 27: '꽁치조림',\n",
       " 28: '꿀떡',\n",
       " 29: '나박김치',\n",
       " 30: '닭갈비',\n",
       " 31: '닭볶음탕',\n",
       " 32: '더덕구이',\n",
       " 33: '도토리묵',\n",
       " 34: '동그랑땡',\n",
       " 35: '동태찌개',\n",
       " 36: '된장찌개',\n",
       " 37: '두부김치',\n",
       " 38: '두부조림',\n",
       " 39: '땅콩조림',\n",
       " 40: '떡갈비',\n",
       " 41: '떡볶이',\n",
       " 42: '라면',\n",
       " 43: '라볶이',\n",
       " 44: '막국수',\n",
       " 45: '만두',\n",
       " 46: '매운탕',\n",
       " 47: '멍게',\n",
       " 48: '메추리알장조림',\n",
       " 49: '멸치볶음',\n",
       " 50: '무국',\n",
       " 51: '무생채',\n",
       " 52: '물냉면',\n",
       " 53: '물회',\n",
       " 54: '미역국',\n",
       " 55: '미역줄기볶음',\n",
       " 56: '배추김치',\n",
       " 57: '백김치',\n",
       " 58: '보쌈',\n",
       " 59: '부추김치',\n",
       " 60: '북엇국',\n",
       " 61: '불고기',\n",
       " 62: '비빔냉면',\n",
       " 63: '비빔밥',\n",
       " 64: '삼겹살',\n",
       " 65: '삼계탕',\n",
       " 66: '새우볶음밥',\n",
       " 67: '새우튀김',\n",
       " 68: '소세지볶음',\n",
       " 69: '송편',\n",
       " 70: '수육',\n",
       " 71: '수정과',\n",
       " 72: '수제비',\n",
       " 73: '숙주나물',\n",
       " 74: '순대',\n",
       " 75: '순두부찌개',\n",
       " 76: '시금치나물',\n",
       " 77: '시래기국',\n",
       " 78: '식혜',\n",
       " 79: '알밥',\n",
       " 80: '애호박볶음',\n",
       " 81: '약과',\n",
       " 82: '약식',\n",
       " 83: '양념게장',\n",
       " 84: '양념치킨',\n",
       " 85: '어묵볶음',\n",
       " 86: '연근조림',\n",
       " 87: '열무김치',\n",
       " 88: '오이소박이',\n",
       " 89: '오징어채볶음',\n",
       " 90: '오징어튀김',\n",
       " 91: '우엉조림',\n",
       " 92: '유부초밥',\n",
       " 93: '육개장',\n",
       " 94: '육회',\n",
       " 95: '잔치국수',\n",
       " 96: '잡곡밥',\n",
       " 97: '잡채',\n",
       " 98: '장어구이',\n",
       " 99: '장조림',\n",
       " 100: '전복죽',\n",
       " 101: '제육볶음',\n",
       " 102: '조개구이',\n",
       " 103: '조기구이',\n",
       " 104: '족발',\n",
       " 105: '주꾸미볶음',\n",
       " 106: '주먹밥',\n",
       " 107: '짜장면',\n",
       " 108: '짬뽕',\n",
       " 109: '쫄면',\n",
       " 110: '찜닭',\n",
       " 111: '총각김치',\n",
       " 112: '추어탕',\n",
       " 113: '칼국수',\n",
       " 114: '코다리조림',\n",
       " 115: '콩국수',\n",
       " 116: '콩나물국',\n",
       " 117: '콩나물무침',\n",
       " 118: '파김치',\n",
       " 119: '파전',\n",
       " 120: '피자',\n",
       " 121: '해물찜',\n",
       " 122: '호박전',\n",
       " 123: '호박죽',\n",
       " 124: '홍어무침',\n",
       " 125: '황태구이',\n",
       " 126: '회무침',\n",
       " 127: '후라이드치킨',\n",
       " 128: '훈제오리'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = train_generator.class_indices\n",
    "class_names = {value:key for key, value in class_names.items()}\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 적절한 batch size, epoch 수 생각\n",
    "num_classes = train_generator.num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def densenet():\n",
    "  densenet = DenseNet201(\n",
    "    include_top=False,\n",
    "    input_shape=(image_size,image_size,3),\n",
    "    weights='imagenet'\n",
    "    )\n",
    "  \n",
    "  \n",
    "  densenet = Sequential([\n",
    "      densenet,\n",
    "      Flatten(), \n",
    "      Dense(256, activation='relu', kernel_regularizer='l2'),\n",
    "      BatchNormalization(),\n",
    "      Dropout(0.2),\n",
    "      Dense(num_classes, activation='softmax')\n",
    "  ])\n",
    "\n",
    "  base_learning_rate = 0.0001\n",
    "\n",
    "  densenet.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=base_learning_rate),\n",
    "                loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "                metrics=['accuracy'])\n",
    "  \n",
    "  return densenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "74836368/74836368 [==============================] - 3s 0us/step\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tb/x7hcv5j94gn9b46c7qc1vfth0000gn/T/ipykernel_35365/2924118385.py:30: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  inception_hist = inception_ml.fit_generator(train_generator,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  50/3223 [..............................] - ETA: 33:26 - loss: 8.6147 - accuracy: 0.0481"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hanhyeongu/miniforge3/envs/deep/lib/python3.8/site-packages/PIL/Image.py:992: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2055/3223 [==================>...........] - ETA: 11:03 - loss: 3.1483 - accuracy: 0.5323"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hanhyeongu/miniforge3/envs/deep/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:845: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3223/3223 [==============================] - 2051s 609ms/step - loss: 2.6510 - accuracy: 0.5792 - val_loss: 1.6105 - val_accuracy: 0.6784\n",
      "Epoch 2/5\n",
      "3223/3223 [==============================] - 1898s 588ms/step - loss: 1.2411 - accuracy: 0.7532 - val_loss: 1.3523 - val_accuracy: 0.7281\n",
      "Epoch 3/5\n",
      "3223/3223 [==============================] - 1892s 587ms/step - loss: 0.9054 - accuracy: 0.8255 - val_loss: 1.3932 - val_accuracy: 0.7233\n",
      "Epoch 4/5\n",
      "3223/3223 [==============================] - 1903s 590ms/step - loss: 0.7066 - accuracy: 0.8743 - val_loss: 1.2776 - val_accuracy: 0.7579\n",
      "Epoch 5/5\n",
      "3223/3223 [==============================] - 1966s 610ms/step - loss: 0.5835 - accuracy: 0.9026 - val_loss: 1.3192 - val_accuracy: 0.7602\n"
     ]
    }
   ],
   "source": [
    "## callback & EarlyStopping\n",
    "\n",
    "epoch = 5\n",
    "\n",
    "cur_dir = '/Users/hanhyeongu/Desktop/codestates/CP1/Yam-Pick_DS/callbacks' # callback 데이터 저장 \n",
    "ckpt_path = os.path.join(cur_dir, 'callback_ckpt')\n",
    "os.makedirs(ckpt_path, exist_ok=True)\n",
    "\n",
    "ckpt_filepath = os.path.join(ckpt_path, 'DenseNet_model_{epoch:04d}-{val_loss:.3f}-{val_accuracy:.3f}.h5')\n",
    "\n",
    "# 특정 기준일 경우에만 저장\n",
    "# 아래 코드는 val_loss가 기존 최고 성능 모델에 비해 낮아질 때만 저장\n",
    "ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=ckpt_filepath, \n",
    "                                                   monitor='val_loss', \n",
    "                                                   save_best_only=True,\n",
    "                                                   save_weights_only=False) # save_weights_only=False 모델 전체 저장\n",
    "\n",
    "# # 모든 epoch 결과 저장\n",
    "# ckpt_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "#     filepath = ckpt_filepath,\n",
    "#     # save_best_only = False, \n",
    "#     save_weights_only = True, # False로 설정할 경우 모델 전체 저장\n",
    "#     save_freq = 'epoch')\n",
    "\n",
    "\n",
    "# loss 가 3번 동안 나아지지 않으면 훈련 종료, val_loss, val_accuracy 사용 가능\n",
    "early_stop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2) \n",
    "\n",
    "inception_ml = densenet()\n",
    "inception_hist = inception_ml.fit_generator(train_generator,\n",
    "          validation_data=val_generator,\n",
    "          epochs=epoch,\n",
    "          callbacks=[ckpt_callback, early_stop_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이후 모델 학습은 너무 많은 시간이 소요되어 패스..!  \n",
    "\n",
    "최고 성능을 보였던 epoch=4모델 선택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callback 결과 불러오기\n",
    "\n",
    "# 가중치만 저장\n",
    "checkpoint_path = '/Users/hanhyeongu/Desktop/codestates/CP1/Yam-Pick_DS/callbacks/callback_ckpt/DenseNet_model_0004-1.278-0.758.h5'\n",
    "model = densenet()\n",
    "model.load_weights(checkpoint_path)\n",
    "model.evaluate_generator(val_generator)\n",
    "\n",
    "# model.fit_generator(train_generator,\n",
    "#                     validation_data=val_generator,\n",
    "#                     epochs=2,\n",
    "#                     callbacks=[ckpt_callback, early_stop_callback]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def model_save_file(model, file_name):\n",
    "    model.save(file_name+'.h5')\n",
    "    with open(file_name+\"_History\", 'wb') as file: # 히스토리 저장\n",
    "        pickle.dump(model.history, file)\n",
    "\n",
    "model_name = '/Users/hanhyeongu/Desktop/codestates/CP1/Yam-Pick_DS/Model_Save/DenseNet201'\n",
    "model_save_file(model, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('deep')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "45131dd49f0cd60e2bde351a431aacc191eee14983541a395265a1766fa1252b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
