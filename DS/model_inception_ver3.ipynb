{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Baseline Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 라이브러리 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
    "from tensorflow.keras.applications.resnet import ResNet50\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, MaxPooling2D\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "\n",
    "from tensorflow.keras.regularizers import L2\n",
    "from tensorflow.keras.optimizers import Adam,RMSprop,SGD,Adamax\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "\n",
    "from silence_tensorflow import silence_tensorflow\n",
    "silence_tensorflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 103131 images belonging to 129 classes.\n",
      "Found 26209 images belonging to 129 classes.\n"
     ]
    }
   ],
   "source": [
    "PATH = '/Users/hanhyeongu/Desktop/codestates/CP1/Korea_Food_Image/'\n",
    "image_size = 150\n",
    "\n",
    "original_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = original_datagen.flow_from_directory(\n",
    "        PATH+'train',\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')\n",
    "\n",
    "val_generator = original_datagen.flow_from_directory(\n",
    "        PATH+'validation',\n",
    "        target_size=(image_size, image_size),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '간장게장',\n",
       " 1: '갈비구이',\n",
       " 2: '갈비찜',\n",
       " 3: '갈비탕',\n",
       " 4: '갈치구이',\n",
       " 5: '갈치조림',\n",
       " 6: '감자전',\n",
       " 7: '감자조림',\n",
       " 8: '감자탕',\n",
       " 9: '갓김치',\n",
       " 10: '건새우볶음',\n",
       " 11: '경단',\n",
       " 12: '계란말이',\n",
       " 13: '계란찜',\n",
       " 14: '고등어구이',\n",
       " 15: '고등어조림',\n",
       " 16: '고사리나물',\n",
       " 17: '고추튀김',\n",
       " 18: '곱창구이',\n",
       " 19: '곱창전골',\n",
       " 20: '김밥',\n",
       " 21: '김치볶음밥',\n",
       " 22: '김치전',\n",
       " 23: '김치찌개',\n",
       " 24: '깍두기',\n",
       " 25: '깻잎장아찌',\n",
       " 26: '꼬막찜',\n",
       " 27: '꽁치조림',\n",
       " 28: '꿀떡',\n",
       " 29: '나박김치',\n",
       " 30: '닭갈비',\n",
       " 31: '닭볶음탕',\n",
       " 32: '더덕구이',\n",
       " 33: '도토리묵',\n",
       " 34: '동그랑땡',\n",
       " 35: '동태찌개',\n",
       " 36: '된장찌개',\n",
       " 37: '두부김치',\n",
       " 38: '두부조림',\n",
       " 39: '땅콩조림',\n",
       " 40: '떡갈비',\n",
       " 41: '떡볶이',\n",
       " 42: '라면',\n",
       " 43: '라볶이',\n",
       " 44: '막국수',\n",
       " 45: '만두',\n",
       " 46: '매운탕',\n",
       " 47: '멍게',\n",
       " 48: '메추리알장조림',\n",
       " 49: '멸치볶음',\n",
       " 50: '무국',\n",
       " 51: '무생채',\n",
       " 52: '물냉면',\n",
       " 53: '물회',\n",
       " 54: '미역국',\n",
       " 55: '미역줄기볶음',\n",
       " 56: '배추김치',\n",
       " 57: '백김치',\n",
       " 58: '보쌈',\n",
       " 59: '부추김치',\n",
       " 60: '북엇국',\n",
       " 61: '불고기',\n",
       " 62: '비빔냉면',\n",
       " 63: '비빔밥',\n",
       " 64: '삼겹살',\n",
       " 65: '삼계탕',\n",
       " 66: '새우볶음밥',\n",
       " 67: '새우튀김',\n",
       " 68: '소세지볶음',\n",
       " 69: '송편',\n",
       " 70: '수육',\n",
       " 71: '수정과',\n",
       " 72: '수제비',\n",
       " 73: '숙주나물',\n",
       " 74: '순대',\n",
       " 75: '순두부찌개',\n",
       " 76: '시금치나물',\n",
       " 77: '시래기국',\n",
       " 78: '식혜',\n",
       " 79: '알밥',\n",
       " 80: '애호박볶음',\n",
       " 81: '약과',\n",
       " 82: '약식',\n",
       " 83: '양념게장',\n",
       " 84: '양념치킨',\n",
       " 85: '어묵볶음',\n",
       " 86: '연근조림',\n",
       " 87: '열무김치',\n",
       " 88: '오이소박이',\n",
       " 89: '오징어채볶음',\n",
       " 90: '오징어튀김',\n",
       " 91: '우엉조림',\n",
       " 92: '유부초밥',\n",
       " 93: '육개장',\n",
       " 94: '육회',\n",
       " 95: '잔치국수',\n",
       " 96: '잡곡밥',\n",
       " 97: '잡채',\n",
       " 98: '장어구이',\n",
       " 99: '장조림',\n",
       " 100: '전복죽',\n",
       " 101: '제육볶음',\n",
       " 102: '조개구이',\n",
       " 103: '조기구이',\n",
       " 104: '족발',\n",
       " 105: '주꾸미볶음',\n",
       " 106: '주먹밥',\n",
       " 107: '짜장면',\n",
       " 108: '짬뽕',\n",
       " 109: '쫄면',\n",
       " 110: '찜닭',\n",
       " 111: '총각김치',\n",
       " 112: '추어탕',\n",
       " 113: '칼국수',\n",
       " 114: '코다리조림',\n",
       " 115: '콩국수',\n",
       " 116: '콩나물국',\n",
       " 117: '콩나물무침',\n",
       " 118: '파김치',\n",
       " 119: '파전',\n",
       " 120: '피자',\n",
       " 121: '해물찜',\n",
       " 122: '호박전',\n",
       " 123: '호박죽',\n",
       " 124: '홍어무침',\n",
       " 125: '황태구이',\n",
       " 126: '회무침',\n",
       " 127: '후라이드치킨',\n",
       " 128: '훈제오리'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = train_generator.class_indices\n",
    "class_names = {value:key for key, value in class_names.items()}\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 적절한 batch size, epoch 수 생각\n",
    "num_classes = train_generator.num_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception():\n",
    "  inception = InceptionV3(\n",
    "    include_top=False,\n",
    "    input_shape=(image_size,image_size,3),\n",
    "    weights='imagenet'\n",
    "    )\n",
    "  \n",
    "  \n",
    "  inception = Sequential([\n",
    "      inception,\n",
    "      Flatten(), \n",
    "      Dense(256, activation='relu', kernel_regularizer='l2'),\n",
    "      BatchNormalization(),\n",
    "      Dropout(0.2),\n",
    "      Dense(num_classes, activation='softmax')\n",
    "  ])\n",
    "\n",
    "  base_learning_rate = 0.0001\n",
    "\n",
    "  inception.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=base_learning_rate),\n",
    "                loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "                metrics=['accuracy'])\n",
    "  \n",
    "  return inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tb/x7hcv5j94gn9b46c7qc1vfth0000gn/T/ipykernel_9517/2655285189.py:30: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  inception_hist = inception_ml.fit_generator(train_generator,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2408/3223 [=====================>........] - ETA: 2:49 - loss: 4.1090 - accuracy: 0.4140"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hanhyeongu/miniforge3/envs/deep/lib/python3.8/site-packages/PIL/TiffImagePlugin.py:845: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3223/3223 [==============================] - 774s 236ms/step - loss: 3.6140 - accuracy: 0.4497 - val_loss: 1.9645 - val_accuracy: 0.5902\n",
      "Epoch 2/5\n",
      "3223/3223 [==============================] - 751s 233ms/step - loss: 1.6031 - accuracy: 0.6548 - val_loss: 1.5368 - val_accuracy: 0.6606\n",
      "Epoch 3/5\n",
      "3223/3223 [==============================] - 753s 234ms/step - loss: 1.1811 - accuracy: 0.7445 - val_loss: 1.5053 - val_accuracy: 0.6794\n",
      "Epoch 4/5\n",
      "3223/3223 [==============================] - 754s 234ms/step - loss: 0.9137 - accuracy: 0.8050 - val_loss: 1.4853 - val_accuracy: 0.6882\n",
      "Epoch 5/5\n",
      "3223/3223 [==============================] - 751s 233ms/step - loss: 0.7377 - accuracy: 0.8474 - val_loss: 1.5307 - val_accuracy: 0.6946\n"
     ]
    }
   ],
   "source": [
    "## callback & EarlyStopping\n",
    "\n",
    "epoch = 5\n",
    "\n",
    "cur_dir = '/Users/hanhyeongu/Desktop/codestates/CP1/Yam-Pick_DS/callbacks' # callback 데이터 저장 \n",
    "ckpt_path = os.path.join(cur_dir, 'callback_ckpt')\n",
    "os.makedirs(ckpt_path, exist_ok=True)\n",
    "\n",
    "ckpt_filepath = os.path.join(ckpt_path, 'inception_model3_{epoch:04d}-{val_loss:.3f}-{val_accuracy:.3f}.h5')\n",
    "\n",
    "# 특정 기준일 경우에만 저장\n",
    "# 아래 코드는 val_loss가 기존 최고 성능 모델에 비해 낮아질 때만 저장\n",
    "ckpt_callback = tf.keras.callbacks.ModelCheckpoint(filepath=ckpt_filepath, \n",
    "                                                   monitor='val_loss', \n",
    "                                                   save_best_only=True,\n",
    "                                                   save_weights_only=False) # save_weights_only=False 모델 전체 저장\n",
    "\n",
    "# # 모든 epoch 결과 저장\n",
    "# ckpt_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "#     filepath = ckpt_filepath,\n",
    "#     # save_best_only = False, \n",
    "#     save_weights_only = True, # False로 설정할 경우 모델 전체 저장\n",
    "#     save_freq = 'epoch')\n",
    "\n",
    "\n",
    "# loss 가 3번 동안 나아지지 않으면 훈련 종료, val_loss, val_accuracy 사용 가능\n",
    "early_stop_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2) \n",
    "\n",
    "inception_ml = inception()\n",
    "inception_hist = inception_ml.fit_generator(train_generator,\n",
    "          validation_data=val_generator,\n",
    "          epochs=epoch,\n",
    "          callbacks=[ckpt_callback, early_stop_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tb/x7hcv5j94gn9b46c7qc1vfth0000gn/T/ipykernel_9517/3286693898.py:7: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
      "  model.evaluate_generator(val_generator)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tb/x7hcv5j94gn9b46c7qc1vfth0000gn/T/ipykernel_9517/3286693898.py:9: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(train_generator,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3223/3223 [==============================] - 776s 235ms/step - loss: 0.7413 - accuracy: 0.8480 - val_loss: 1.4567 - val_accuracy: 0.7067\n",
      "Epoch 2/5\n",
      "3223/3223 [==============================] - 744s 231ms/step - loss: 0.6097 - accuracy: 0.8776 - val_loss: 1.4824 - val_accuracy: 0.7099\n",
      "Epoch 3/5\n",
      "3223/3223 [==============================] - 743s 231ms/step - loss: 0.5328 - accuracy: 0.8967 - val_loss: 1.5324 - val_accuracy: 0.7064\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x40157d4c0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# callback 결과 불러오기\n",
    "\n",
    "# 가중치만 저장\n",
    "checkpoint_path = '/Users/hanhyeongu/Desktop/codestates/CP1/Yam-Pick_DS/callbacks/callback_ckpt/inception_model3_0004-1.485-0.688.h5'\n",
    "model = inception()\n",
    "model.load_weights(checkpoint_path)\n",
    "model.evaluate_generator(val_generator)\n",
    "\n",
    "model.fit_generator(train_generator,\n",
    "                    validation_data=val_generator,\n",
    "                    epochs=5,\n",
    "                    callbacks=[ckpt_callback, early_stop_callback]) \n",
    "\n",
    "\n",
    "# 모델 전체 저장 \n",
    "# checkpoint_path = '/content/drive/MyDrive/CS/CP1/callback/callback_ckpt/mobilenet_0001-0.587-0.846.h5'\n",
    "# model = tf.keras.models.load_model(checkpoint_path)\n",
    "# model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=base_learning_rate),\n",
    "#                 loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n",
    "#                 metrics=['accuracy']) # 옵티마이저의 상태는 유지되지 않으므로 다시 compile\n",
    "# model.fit_generator(train_generator,\n",
    "#                     validation_data=val_generator,\n",
    "#                     epochs=epoch,\n",
    "#                     callbacks=[ckpt_callback, early_stop_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 94). These functions will not be directly callable after loading.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "def model_save_file(model, file_name):\n",
    "    model.save(file_name+'.h5')\n",
    "    with open(file_name+\"_History\", 'wb') as file: # 히스토리 저장\n",
    "        pickle.dump(model.history, file)\n",
    "\n",
    "model_name = '/Users/hanhyeongu/Desktop/codestates/CP1/Yam-Pick_DS/Model_Save/inception_129menu ver2'\n",
    "model_save_file(model, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('deep')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "45131dd49f0cd60e2bde351a431aacc191eee14983541a395265a1766fa1252b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
